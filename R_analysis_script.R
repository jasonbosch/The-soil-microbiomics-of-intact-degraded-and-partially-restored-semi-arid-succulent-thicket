#This is the script which generates the necessary data and performs the analyses for our paper on the semi-arid succulent thicket (Albany Subtropical Thicket).
#It requires the amplicon sequencing data generated by the QIIME2 analysis script.
#Written by: Jason Bosch
#Last update: 07/06/2021

###############
####SET UP#####
###############

##The locations for the results folder and the raw data that needs to be imported will have to be adjusted to suit your setup.##

#Move to correct results folder
setwd("~/PostDoc/04_Albany_Thicket_Restoration_Soil_Microbiome_Project/Analysis/")

#Load the necessary libraries
library(phyloseq)
library(ggplot2)
library(stringr)
library(pheatmap)
library(RColorBrewer)
library(vegan)
library(gridExtra)
library(NetCoMi)
library(ggsignif)
library(lubridate)
library(ggrepel)

###Sequencing Data###

#Import QIIME2 taxonomy function
import_qiime2_taxonomy <- function(qiime2_taxonomy) {
  taxonomy_cleaning <- as.data.frame(qiime2_taxonomy[,1])
  taxonomy_cleaning[,1] <- gsub("[a-z]__","",taxonomy_cleaning[,1])
  taxonomy_split <- as.data.frame(matrix(nrow = 1,ncol = 7))
  for (n in 1:nrow(taxonomy_cleaning)) {
    taxonomy_split[n,] <- str_split_fixed(taxonomy_cleaning[n,1],"; ", n = 7)
  }
  colnames(taxonomy_split) <- c("Domain","Phylum","Class","Order","Family","Genus","Species")
  rownames(taxonomy_split) <- rownames(qiime2_taxonomy)
  tax_table(as.matrix(taxonomy_split))
}

#Import the data for the first experiment
otu_table_raw <- read.table("~/PostDoc/04_Albany_Thicket_Restoration_Soil_Microbiome_Project/QIIME2_results/G174-184705525/export/OTU.tsv", header = TRUE, row.names = 1, sep = "\t", comment.char = "#")
metadata_raw <- read.table ("~/PostDoc/04_Albany_Thicket_Restoration_Soil_Microbiome_Project/Analysis/Albany_metadata.csv", header = TRUE, row.names = 1, sep = ",")
colnames(metadata_raw) <- c("Zone","Transect","Row","Nucleic_acid","pH.KCl","PBray1","PBray2","Na","K","Ca","Mg","percent.Ca","percent.Mg","percent.K","percent.Na","Ratio.Ca.Mg","Ca.Mg.over.K","Ratio.Mg.K","S.Value","ratio.Na.K","CEC","Density","S","Clay","Silt","Sand","NO3","NH4","C","RH.Avg","Temp.Avg","RH.Max","RH.Min","Temp.Max","Temp.Min")
metadata_raw$Zone <- gsub("Partial_restoration","Restored",metadata_raw$Zone)
G174_otu_final = otu_table(as.matrix(otu_table_raw), taxa_are_rows = TRUE)
metadata_final = sample_data(metadata_raw)

#Import the data for the second experiment
otu_table_raw <- read.table("~/PostDoc/04_Albany_Thicket_Restoration_Soil_Microbiome_Project/QIIME2_results/G174R-189359172/export/OTU.tsv", header = TRUE, row.names = 1, sep = "\t", comment.char = "#")
G174R_otu_final = otu_table(as.matrix(otu_table_raw), taxa_are_rows = TRUE)

#Bring in the QIIME2 taxonomy
G174_QIIME2_taxonomy_final = import_qiime2_taxonomy(read.table("~/PostDoc/04_Albany_Thicket_Restoration_Soil_Microbiome_Project/QIIME2_results/G174-184705525/export/taxonomy.tsv", header = TRUE, row.names = 1, sep = "\t",))
G174R_QIIME2_taxonomy_final = import_qiime2_taxonomy(read.table("~/PostDoc/04_Albany_Thicket_Restoration_Soil_Microbiome_Project/QIIME2_results/G174R-189359172/export/taxonomy.tsv", header = TRUE, row.names = 1, sep = "\t",))

#Join it all into a phyloseq object
#No tree because it will need to be merged later
G174_physeq_qiime = phyloseq(G174_otu_final, metadata_final, G174_QIIME2_taxonomy_final)
G174R_physeq_qiime = phyloseq(G174_otu_final, metadata_final, G174R_QIIME2_taxonomy_final)

##Merge them together
physeq_exp <- merge_phyloseq(G174_physeq_qiime,G174R_physeq_qiime)

###iButton Data###

#Bring in the data
data <- read.csv("~/PostDoc/04_Albany_Thicket_Restoration_Soil_Microbiome_Project/iButton/iButton_data.csv",stringsAsFactors = F)

#Fix column name
colnames(data)[3] <- "Zone"

#Correct RH values beyond 100
data[which(data$RH > 100),"RH"] <- 100

#Change the date and time to POSIXct compliant data and time
for (x in 1:nrow(data)) {
  data[x,"Date"] <- as.POSIXct(strptime(data[x,"DateTime"],format = "%Y/%m/%d %H:%M"))
}

#Create a time column
Times <- strftime(data$Date, format="%H:%M:%S")
Times <- as.POSIXct(Times, format="%H:%M:%S")
data[,"Time"] <- Times

###################
#####ANALYSIS######
###################

#Filtering to remove any incorrect Eukaryote sequences
physeq_exp = subset_taxa(physeq_exp, tax_table(physeq_exp) != "Eukaryota")

#Site colours
#https://colorbrewer2.org/#type=qualitative&scheme=Dark2&n=3
site_colours <- c("#66c2a5","#fc8d62","#8da0cb")
names(site_colours) <- c("Intact","Degraded","Restored")

#####################

###Alpha diversity###

#Calculate the alpha diversity values
alpha_diversity = estimate_richness(physeq_exp)

#Add in metadata to alpha diversity to allow groupings
table_alpha_diversity <- merge.data.frame(alpha_diversity, metadata_final, by = "row.names")

#Observed species
#Analysis of variance and Tukey Honest Significant Differences test. 
aov.observed = aov(Observed ~ Zone, data=table_alpha_diversity)
summary(aov.observed)
TukeyHSD(aov.observed)
#Box plot
Alpha_observed <- ggplot (table_alpha_diversity, aes( x= Zone, y = Observed, fill = Zone)) + geom_boxplot() + 
  geom_point (aes(fill = Zone), size = 2, position = position_jitterdodge()) + theme_classic() + 
  scale_fill_manual(values = site_colours) +
  theme(legend.position = "none") +
  geom_signif(comparisons = list(c("Intact","Degraded"),c("Degraded","Restored"),c("Intact","Restored")), y_position = c(max(table_alpha_diversity$Observed)*1.05,(max(table_alpha_diversity$Observed))*1.1,(max(table_alpha_diversity$Observed))*1.15),map_signif_level=TRUE, colour="black")
  
#Shannon Index (recommended: https://drive5.com/usearch/manual/diversity_metrics_recommended.html)
#Analysis of variance and Tukey Honest Significant Differences test. 
aov.Shannon = aov(Shannon ~ Zone, data=table_alpha_diversity)
summary(aov.Shannon)
TukeyHSD(aov.Shannon)
#Box plot
Alpha_Shannon = ggplot (table_alpha_diversity, aes( x= Zone, y = Shannon, fill = Zone)) + geom_boxplot() + 
  geom_point (aes(fill = Zone), size = 2, position = position_jitterdodge())+theme_classic() + 
  scale_fill_manual(values = site_colours) + 
  theme(legend.position = "none") +
  geom_signif(comparisons = list(c("Intact","Degraded"),c("Degraded","Restored"),c("Intact","Restored")), y_position = c(max(table_alpha_diversity$Shannon)*1.005,(max(table_alpha_diversity$Shannon))*1.01,(max(table_alpha_diversity$Shannon))*1.015),map_signif_level=TRUE, colour="black")

#Save figure
Alpha_observed <- Alpha_observed + labs(tag = "A")
Alpha_Shannon <- Alpha_Shannon + labs(tag = "B")
Alpha_fig <- grid.arrange(Alpha_observed,Alpha_Shannon,ncol=2)
ggsave(filename = paste("Supplementary Figure S5.eps",sep=""), Alpha_fig, width = 8, height = 4.5, dpi = 300)

#####################

###Beta diversity (through Phyloseq)###

#Going to use proportions here rather as this will remove variation in library sizes which doesn't happen with log transformation
physeq_exp_transformed = transform_sample_counts(physeq_exp, function (x) x/sum(x))

#Using weighted Jaccard as recommended: https://drive5.com/usearch/manual/diversity_metrics_recommended.html
sampleDist = phyloseq::distance(physeq = physeq_exp_transformed,method = "jaccard")

sampleDistMatrix <- as.matrix(sampleDist)
rownames(sampleDistMatrix) <- paste(physeq_exp_transformed@sam_data$Zone,sample_names(physeq_exp_transformed),sep = "_")
colnames(sampleDistMatrix) <- paste(physeq_exp_transformed@sam_data$Zone,sample_names(physeq_exp_transformed),sep = "_")
annotrow <- data.frame(row.names = rownames(sampleDistMatrix),Zone = physeq_exp_transformed@sam_data$Zone)
colors <- colorRampPalette( rev(brewer.pal(9, "Reds")) )(255)
heatmap_jaccard <- pheatmap(sampleDistMatrix,
                            clustering_distance_rows=sampleDist,
                            clustering_distance_cols=sampleDist,
                            color = colors,
                            annotation_col = annotrow,
                            annotation_colors = list(Zone = site_colours),
                            annotation_row = annotrow,
                            annotation_names_col = FALSE,	
                            annotation_names_row = FALSE
                            )
ggsave(filename = "Supplementary Figure S6.eps", heatmap_jaccard, width = 8, height = 6, dpi = 300)

#Plot PCoA
#https://micca.readthedocs.io/en/latest/phyloseq.html
ordination = ordinate(physeq_exp_transformed, method="PCoA", distance=sampleDist)
PCoA_phyloseq_Jaccard <- plot_ordination(physeq_exp_transformed, ordination, color="Zone") + theme(aspect.ratio=1) + scale_colour_manual(values = site_colours) + theme_minimal() + geom_point(size=3) + stat_ellipse()

#Checks whether the samples have the same centroid. Null hypothesis is same centroid.
#https://deneflab.github.io/MicrobeMiseq/demos/mothur_2_phyloseq.html#permanova
#R2 shows how much is explained, residuals are unexplained variation.
sampledf <- data.frame(sample_data(physeq_exp_transformed))
adonis2(sampleDist ~ Zone, data = sampledf, permutations = 1000)
beta <- betadisper(sampleDist, sampledf$Zone)
permutest(beta)
TukeyHSD(beta)

#Figure will be combined with another figure later in the script

###Relative Abundance###

#Relative abundance graph
physeq_RA = transform_sample_counts(physeq_exp, function (x) x/sum(x))
#Phylum
physeq_RA_phylum = tax_glom (physeq_RA, taxrank = "Phylum",NArm = FALSE)
physeq_dominant <- merge_taxa(physeq_RA_phylum,taxa_names(filter_taxa(physeq_RA_phylum, function(x) mean(x) < 0.01, TRUE)))
#physeq_dominant= filter_taxa(physeq_RA_phylum, function(x) mean(x) > 0.01, TRUE)
phylum_colours <- colorRampPalette(brewer.pal(12, "Paired"))(length(unique(tax_table(physeq_dominant)[,"Phylum"])))
names(phylum_colours) <- sort(unique(tax_table(physeq_dominant)[,"Phylum"]))
RA_bact = plot_bar(physeq_dominant, fill = "Phylum") + labs(x="Sample", y = "Abundance") + facet_wrap(~Zone, scales = "free_x", nrow = 1) + geom_bar(stat = "identity", position = "fill", colour = "black") + scale_fill_manual(values = phylum_colours)
#Genus
physeq_RA_genus = tax_glom (physeq_RA, taxrank = "Genus",NArm = FALSE)
physeq_dominant_genus <- merge_taxa(physeq_RA_genus,taxa_names(filter_taxa(physeq_RA_genus, function(x) mean(x) < 0.01, TRUE)))
genus_colours <- colorRampPalette(brewer.pal(12, "Paired"))(length(unique(tax_table(physeq_dominant_genus)[,"Genus"])))
names(genus_colours) <- sort(unique(tax_table(physeq_dominant_genus)[,"Genus"]))
RA_bact_genus = plot_bar(physeq_dominant_genus, fill = "Genus") + labs(x="Sample", y = "Abundance") + facet_wrap(~Zone, scales = "free_x", nrow = 1) + geom_bar(stat = "identity", position = "fill", colour = "black")  + scale_fill_manual(values = genus_colours)
physeq_dominant_genus_sub= filter_taxa(physeq_RA_genus, function(x) mean(x) > 0.01, TRUE)
RA_bact_genus_sub = plot_bar(physeq_dominant_genus_sub, fill = "Genus") + labs(x="Sample", y = "Abundance") + facet_wrap(~Zone, scales = "free_x", nrow = 1) + geom_bar(stat = "identity", position = "fill", colour = "black")  + scale_fill_manual(values = genus_colours)

#Figure
RA_bact_fig = plot_bar(physeq_dominant, fill = "Phylum") + labs(x="Sample", y = "Abundance") + facet_wrap(~Zone, scales = "free_x", nrow = 1) + geom_bar(stat = "identity", position = "fill", colour = "black") + scale_fill_manual(values = phylum_colours) + labs(tag = "A")
RA_bact_genus_sub_fig = plot_bar(physeq_dominant_genus_sub, fill = "Genus") + labs(x="Sample", y = "Abundance") + facet_wrap(~Zone, scales = "free_x", nrow = 1) + geom_bar(stat = "identity", position = "fill", colour = "black")  + scale_fill_manual(values = genus_colours) + labs(tag = "B")
RA_fig <- grid.arrange(RA_bact_fig,RA_bact_genus_sub_fig,ncol=2)
ggsave(filename = paste("Figure 3.eps",sep=""), RA_fig, width = 14, height = 6.75, dpi = 300)

#Create a table to compare relative abundance of genera
RA_table_genus_2 <- as.data.frame(otu_table(physeq_dominant_genus))
tidy_RA_genus_2 <- data.frame()
for (x in 1:length(colnames(RA_table_genus_2))) {
  current <- as.data.frame(RA_table_genus_2[,x]) #RA
  current[,2] <- colnames(RA_table_genus_2)[x] #site
  current[,3] <- sample_data(physeq_dominant_genus)[rownames(sample_data(physeq_dominant_genus))==colnames(RA_table_genus_2)[x],"Zone"] #Zone
  current[,4] <- tax_table(physeq_dominant_genus)[,"Genus"] #Genus
  tidy_RA_genus_2 <- rbind(tidy_RA_genus_2,current)
}
colnames(tidy_RA_genus_2) <- c("RA","Site","Zone","Genus")
#remove the unlabelled
tidy_RA_genus_2 <- subset(tidy_RA_genus_2,!tidy_RA_genus_2$Genus=="")

#Figure
Genus_sig <- ggplot(tidy_RA_genus_2, aes(x = Zone, y = RA)) + geom_boxplot(aes(fill=Zone)) + 
  theme_minimal() + theme(legend.position = "none", plot.title = element_text(hjust = 0.5)) +  labs(title = "Relative abundance of Genera") +
  geom_signif(comparisons = list(c("Intact","Degraded"),c("Degraded","Restored"),c("Intact","Restored")),map_signif_level=TRUE, colour="black",step_increase = 0.2) +
  scale_fill_manual(values = site_colours) + facet_wrap(~Genus) + ylim(0,0.15)
ggsave(filename = paste("Supplementary Figure S7.eps",sep=""), Genus_sig, width = 16, height = 9, dpi = 300)

##Core Microbiome##
#Own design (with Pedro's advice)

#Want to combine everything at genus level
physeq_exp_gen <- tax_glom(physeq_exp, taxrank = "Genus",NArm = FALSE)

#Now we get the site prevalence and the OTU
prevelancedf = apply(X = otu_table(physeq_exp_gen), MARGIN = 1, FUN = function(x){sum(x > 0)})
prevelancedf = data.frame(Sites_present = prevelancedf, tax_table(physeq_exp_gen))

#Limit ourselves to only those present in 33 of 35 of the sites (> 94%)
core_community_genus <- subset(prevelancedf,prevelancedf$Sites_present >= 33)

#Write table
write.table(core_community_genus, file = "Supplementary Table S3.csv",quote = T,row.names = F, col.names = T, sep = ",")


#What about in a single zone?
physeq_intact <- subset_samples(physeq_exp, grepl("Intact",physeq_exp@sam_data$Zone))
physeq_degraded <- subset_samples(physeq_exp, grepl("Degraded",physeq_exp@sam_data$Zone))
physeq_partially_restored <- subset_samples(physeq_exp, grepl("Restored",physeq_exp@sam_data$Zone))

physeq_intact <- tax_glom(physeq_intact, taxrank = "Genus",NArm = FALSE)
physeq_degraded <- tax_glom(physeq_degraded, taxrank = "Genus",NArm = FALSE)
physeq_partially_restored <- tax_glom(physeq_partially_restored, taxrank = "Genus",NArm = FALSE)

prevelancedf_intact = apply(X = otu_table(physeq_intact), MARGIN = 1, FUN = function(x){sum(x > 0)})
prevelancedf_intact = data.frame(Sites_present = prevelancedf_intact, tax_table(physeq_intact))
prevelancedf_degraded = apply(X = otu_table(physeq_degraded), MARGIN = 1, FUN = function(x){sum(x > 0)})
prevelancedf_degraded = data.frame(Sites_present = prevelancedf_degraded, tax_table(physeq_degraded))
prevelancedf_partially_restored = apply(X = otu_table(physeq_partially_restored), MARGIN = 1, FUN = function(x){sum(x > 0)})
prevelancedf_partially_restored = data.frame(Sites_present = prevelancedf_partially_restored, tax_table(physeq_partially_restored))

core_community_genus_intact <- subset(prevelancedf_intact,prevelancedf_intact$Sites_present >= round((0.95 * length(sample_names(physeq_intact)))))
core_community_genus_degraded <- subset(prevelancedf_degraded,prevelancedf_degraded$Sites_present >= round((0.95 * length(sample_names(physeq_degraded)))))
core_community_genus_partially_restored <- subset(prevelancedf_partially_restored,prevelancedf_partially_restored$Sites_present >= round((0.95 * length(sample_names(physeq_partially_restored)))))

write.table(core_community_genus_intact, file = "Supplementary Table S4.csv",quote = T,row.names = F, col.names = T, sep = ",")
write.table(core_community_genus_degraded, file = "Supplementary Table S5.csv",quote = T,row.names = F, col.names = T, sep = ",")
write.table(core_community_genus_partially_restored, file = "Supplementary Table S6.csv",quote = T,row.names = F, col.names = T, sep = ",")

#A few stats about the core community

#What percent is the core community?
nrow(core_community_genus)/nrow(prevelancedf[prevelancedf$Sites_present>=1,])*100
#Only 9.8659% at genus level is found in >94% samples, remarkably low.
nrow(core_community_genus_intact)/nrow(prevelancedf_intact[prevelancedf_intact$Sites_present>=1,])*100
#13.57883
nrow(core_community_genus_degraded)/nrow(prevelancedf_degraded[prevelancedf_degraded$Sites_present>=1,])*100
#22.10386
nrow(core_community_genus_partially_restored)/nrow(prevelancedf_partially_restored[prevelancedf_partially_restored$Sites_present>=1,])*100
#30.48601

#How does the core compare to the overall relative abundance?
(sum(otu_table(prune_taxa(rownames(otu_table(physeq_exp_gen))%in%rownames(core_community_genus),physeq_exp_gen)))/sum(otu_table(physeq_exp_gen)))*100
#The core community accounts for 70.2851% of the reads
(sum(otu_table(prune_taxa(rownames(otu_table(physeq_intact))%in%rownames(core_community_genus_intact),physeq_intact)))/sum(otu_table(physeq_intact)))*100
#74.95424
(sum(otu_table(prune_taxa(rownames(otu_table(physeq_degraded))%in%rownames(core_community_genus_degraded),physeq_degraded)))/sum(otu_table(physeq_degraded)))*100
#88.42846
(sum(otu_table(prune_taxa(rownames(otu_table(physeq_partially_restored))%in%rownames(core_community_genus_partially_restored),physeq_partially_restored)))/sum(otu_table(physeq_partially_restored)))*100
#86.40424

#Also of interest will be the unique members of the core community.
#i.e. taxa that are in the core community of a site but absent in 90% of the samples from other sites.
unique_community_intact <- subset(core_community_genus_intact,
                                  #taxids of core community
                                  rownames(core_community_genus_intact)
                                  #in
                                  %in%
                                    #the combination taxids of those not present in others
                                    unique(c(rownames(prevelancedf_degraded)[prevelancedf_degraded$Sites_present <= round((0.1 * length(sample_names(physeq_degraded))))],
                                             rownames(prevelancedf_partially_restored)[prevelancedf_partially_restored$Sites_present <= round((0.1 * length(sample_names(physeq_partially_restored))))])))
unique_community_degraded <- subset(core_community_genus_degraded,
                                    #taxids of core community
                                    rownames(core_community_genus_degraded)
                                    #in
                                    %in%
                                      #the combination taxids of those not present in others
                                      unique(c(rownames(prevelancedf_intact)[prevelancedf_intact$Sites_present <= round((0.1 * length(sample_names(physeq_intact))))],
                                               rownames(prevelancedf_partially_restored)[prevelancedf_partially_restored$Sites_present <= round((0.1 * length(sample_names(physeq_partially_restored))))])))
unique_community_partially_restored <- subset(core_community_genus_partially_restored,
                                              #taxids of core community
                                              rownames(core_community_genus_partially_restored)
                                              #in
                                              %in%
                                                #the combination taxids of those not present in others
                                                unique(c(rownames(prevelancedf_intact)[prevelancedf_intact$Sites_present <= round((0.1 * length(sample_names(physeq_intact))))],
                                                         rownames(prevelancedf_degraded)[prevelancedf_degraded$Sites_present <= round((0.1 * length(sample_names(physeq_degraded))))])))

#Also want to know the RA of unique taxa
for (x in rownames(unique_community_intact)) {
  unique_community_intact[x,"RA"] <- sum(otu_table(physeq_intact)[x,])/sum(otu_table(physeq_intact))
  #unique_community_intact[x,"mean_RA"] <- mean(otu_table(physeq_intact))/mean(colSums(otu_table(physeq_intact)))
  #Below only does avg. RA where reads were detected. Those are only taxa that contribute to the total reads in this group, so seems better to use them only rather than irrelevant taxa from other samples.
  unique_community_intact[x,"mean_RA"] <- mean(otu_table(physeq_intact)[rowSums(otu_table(physeq_intact))>0,])/mean(colSums(otu_table(physeq_intact)))
}
for (x in rownames(unique_community_degraded)) {
  unique_community_degraded[x,"RA"] <- sum(otu_table(physeq_degraded)[x,])/sum(otu_table(physeq_degraded))
  #unique_community_degraded[x,"mean_RA"] <- mean(otu_table(physeq_degraded))/mean(colSums(otu_table(physeq_degraded)))
  unique_community_degraded[x,"mean_RA"] <- mean(otu_table(physeq_degraded)[rowSums(otu_table(physeq_degraded))>0,])/mean(colSums(otu_table(physeq_intact)))
}
for (x in rownames(unique_community_partially_restored)) {
  unique_community_partially_restored[x,"RA"] <- sum(otu_table(physeq_partially_restored)[x,])/sum(otu_table(physeq_partially_restored))
  #unique_community_partially_restored[x,"mean_RA"] <- mean(otu_table(physeq_partially_restored))/mean(colSums(otu_table(physeq_partially_restored)))
  unique_community_partially_restored[x,"mean_RA"] <- mean(otu_table(physeq_partially_restored)[rowSums(otu_table(physeq_partially_restored))>0,])/mean(colSums(otu_table(physeq_intact)))
}

#Save table
unique_community_intact["Zone"] <- "Intact"
unique_community_degraded["Zone"] <- "Degraded"
unique_community_partially_restored["Zone"] <- "Restored"
uniques <- rbind(unique_community_intact,unique_community_degraded,unique_community_partially_restored)
write.table(uniques, file = "Supplementary Table S7.csv",quote = T,row.names = F, col.names = T, sep = ",")

###Lefse###
#This is supposed to tell us what is differentially abundant and important
#https://huttenhower.sph.harvard.edu/galaxy/

#Preparation of file
physeq_RA = transform_sample_counts(physeq_exp, function (x) x/sum(x))
Lefse <- as.data.frame(otu_table(physeq_RA))
Lefse_labels <- as.data.frame(tax_table(physeq_RA))
Lefse_labels[,"Full_name"] <- paste(Lefse_labels[,"Domain"],Lefse_labels[,"Phylum"],Lefse_labels[,"Class"],Lefse_labels[,"Order"],Lefse_labels[,"Family"],Lefse_labels[,"Genus"],sep="|")
Lefse[,"Full_name"] <- Lefse_labels[,"Full_name"]

#Will need some new rows which provide the necessary metadata. year, rep, id
Lefse_metadata <- data.frame()
Lefse_metadata[1,1:length(sample_names(physeq_RA))] <-paste(physeq_RA@sam_data$Zone)
Lefse_metadata[2,1:length(sample_names(physeq_RA))] <-sample_names(physeq_RA)
Lefse_metadata[,"Full_name"] <- c("Zone","id")
colnames(Lefse_metadata) <-colnames(Lefse)

#Combine them for the final files
Lefse_Final <- rbind(Lefse_metadata,Lefse)
Lefse_Final <- Lefse_Final[,c(ncol(Lefse_Final),1:(ncol(Lefse_Final)-1))]

#Write the file that will be submitted for Lefse
write.table(Lefse_Final,file = "Lefse_Final.tsv",row.names = FALSE,col.names = FALSE, quote = FALSE, sep = "\t")

###RDA###

#Make data comparable with relative abundance and then glom to phylum level
physeq_RA = transform_sample_counts(physeq_exp, function (x) x/sum(x))
physeq_RA_phylum = tax_glom (physeq_RA, taxrank = "Phylum",NArm = FALSE)

#Normalise the soil chemistry
physeq_RA_phylum@sam_data[,5:ncol(metadata_raw)] <- decostand(physeq_RA_phylum@sam_data[,5:ncol(metadata_raw)], "stand")
      
# #Test for which variables should be included.
# initial.rda <- ordinate(physeq_RA_phylum,method = "RDA", formula = as.formula(paste("Zone ~ ", paste(colnames(metadata_raw)[5:ncol(metadata_raw)],collapse="+"))))
# initial.rda1 <- ordinate(physeq_RA_phylum,method = "RDA", formula = Zone ~ 1)
# step.res <- ordistep(initial.rda1, scope=formula(initial.rda), direction="forward")
# stepr2.res <- ordiR2step(initial.rda1, scope=formula(initial.rda), direction="forward")
# step.res$anova
# stepr2.res$anova
  
#Ratio.Ca.Mg and Density appeared in both models.
rda_final<-ordinate(physeq_RA_phylum,method = "RDA", formula = Zone ~ Ratio.Ca.Mg + Density)

#Stats for the final RDA
anova(rda_final, steps=1000)
anova(rda_final, by="axis", step=1000)
anova(rda_final, by="terms", step=1000)

#To get arrows: https://github.com/joey711/phyloseq/issues/274
# Now add the environmental variables as arrows
arrowmat = vegan::scores(rda_final, display = "bp")
# Add labels, make a data.frame
arrowdf <- data.frame(labels = rownames(arrowmat), arrowmat)
# Define the arrow aesthetic mapping
arrow_map = aes(xend = RDA1, yend = RDA2, x = 0, y = 0, shape = NULL, color = NULL)
label_map = aes(x = 1.1 * RDA1, y = 1.1 * RDA2, shape = NULL, color = NULL, label = labels)
# Make a new graphic
arrowhead = arrow(length = unit(0.02, "npc"))

#To keep RDA in the same colour scheme
rda_colours <- c("#66c2a5","#fc8d62","#8da0cb","#a6611a")
names(rda_colours) <- c("Intact","Degraded","Restored","Taxa")

RDA_RA_Phylum_no_overlap <- plot_ordination(physeq_RA_phylum,rda_final,type = "biplot", color = "Zone") + geom_text(mapping = aes(label = Phylum), size = 4,vjust=1.5,check_overlap = TRUE) + geom_segment(arrow_map, size = 0.5, data = arrowdf, color = "black", arrow = arrowhead) + geom_text_repel(label_map, size = 4, data = arrowdf) + scale_colour_manual(values = rda_colours) + theme_minimal() + theme(legend.position = "none")

#Do the RDA for Genus level

#Make data comparable with relative abundance and then glom to phylum level
physeq_RA_genus = tax_glom (physeq_RA, taxrank = "Genus",NArm = FALSE)

#Normalise the soil chemistry
physeq_RA_genus@sam_data[,5:ncol(metadata_raw)] <- decostand(physeq_RA_genus@sam_data[,5:ncol(metadata_raw)], "stand")

# #Test for which variables should be included.
# initial.rda <- ordinate(physeq_RA_genus,method = "RDA", formula = as.formula(paste("Zone ~ ", paste(colnames(metadata_raw)[5:ncol(metadata_raw)],collapse="+"))))
# initial.rda1 <- ordinate(physeq_RA_genus,method = "RDA", formula = Zone ~ 1)
# step.res <- ordistep(initial.rda1, scope=formula(initial.rda), direction="forward")
# stepr2.res <- ordiR2step(initial.rda1, scope=formula(initial.rda), direction="forward")
# step.res$anova
# stepr2.res$anova

#Both models included Density, pH.KCl, Ratio.CA.Mg and Clay. CEC and Ca appeared in one.
#Ca, CEC and and Clay were not significant when included in the final model and were removed.
rda_final<-ordinate(physeq_RA_genus, method = "RDA", formula = Zone ~ Density + pH.KCl + Ratio.Ca.Mg)

#Stats for the final RDA
anova(rda_final, steps=1000)
anova(rda_final, by="axis", step=1000)
anova(rda_final, by="terms", step=1000)

#To get arrows: https://github.com/joey711/phyloseq/issues/274
# Now add the environmental variables as arrows
arrowmat = vegan::scores(rda_final, display = "bp")
# Add labels, make a data.frame
arrowdf <- data.frame(labels = rownames(arrowmat), arrowmat)
# Define the arrow aesthetic mapping
arrow_map = aes(xend = RDA1, yend = RDA2, x = 0, y = 0, shape = NULL, color = NULL)
label_map = aes(x = 1.1 * RDA1, y = 1.1 * RDA2, shape = NULL, color = NULL, label = labels)
# Make a new graphic
arrowhead = arrow(length = unit(0.02, "npc"))

RDA_RA_Genus_no_overlap <- plot_ordination(physeq_RA_genus,rda_final,type = "biplot", color = "Zone") + geom_text(mapping = aes(label = Genus), size = 4,vjust=1.5,check_overlap = TRUE) + geom_segment(arrow_map, size = 0.5, data = arrowdf, color = "black", arrow = arrowhead) + geom_text_repel(label_map, size = 4, data = arrowdf) + scale_colour_manual(values = rda_colours) + theme_minimal()

#RDA figures will be combined with other data further in the script.

#####

###Co-occurrence networks###

#Preprocessing
#Merge to genus
physeq_exp_pruned_genus <- tax_glom (physeq_exp, taxrank = "Genus",NArm = FALSE)
#Remove taxa with less than 70 reads; i.e. 2 per sample on average.
physeq_exp_pruned_genus_filt <- subset_taxa(physeq_exp_pruned_genus, rowSums(otu_table(physeq_exp_pruned_genus)) >= 70)

#Make a network of the different conditions. Only doing main ones.
physeq_exp_pruned_genus_filt_group <- subset_samples(physeq_exp_pruned_genus_filt, sample_data(physeq_exp_pruned_genus_filt)$Zone%in%c("Intact","Degraded"))

#Create a partial network leaving only the 50 taxa with the highest variance. Takes too long to do a full network and would probably be uninterpretable anyway.
network_partial <- netConstruct(physeq_exp_pruned_genus_filt_group, group = sample_data(physeq_exp_pruned_genus_filt_group)$Zone%in%"Intact", filtTax = "highestVar", filtTaxPar = list(highestVar = 50), measure = "ccrepe",measurePar = list(min.subj = 15), normMethod = "fractions", sparsMethod = "softThreshold", seed = 20190101)

#Make sure nodes are colourblind safe. Edges are assigned in the functions.
netcolours <- brewer.pal(6, "Dark2")

#Analyse partial network and plot
netprops_partial <- netAnalyze(network_partial, clustMethod = "cluster_fast_greedy")
cairo_ps(file = "Fig6.eps", width = 12, height = 6.75, onefile = FALSE, fallback_resolution = 300)
partial.plot <- plot(netprops_partial, sameLayout = FALSE, layoutGroup = 1, groupNames = c("Intact","Degraded"), labels = as.character(tax_table(physeq_exp_pruned_genus_filt_group)[colnames(network_partial$countMat1),"Genus"]),
                     shortenLabels = "none", labelScale = FALSE, rmSingles = "inboth", nodeTransp = 65, borderCol = "gray60", hubTransp = 50, hubBorderWidth = 2, hubBorderCol = "gray80",
                     edgeTranspLow = 70, edgeTranspHigh = 30, cexLabels = 0.8, showTitle = TRUE, mar = c(1,3,3,4),
                     colorVec = netcolours, posCol = "#2c7bb6", negCol = "#d7191c")
dev.off()

#Create a table to see how the different ASVs are distributed between intact and degraded

#Create an RA phyloseq object for the network taxa (Want to compare all 3 zones)
# physeq_net_RA_genus <- transform_sample_counts(physeq_exp_pruned_genus_filt_group, function (x) x/sum(x))
physeq_net_RA_genus <- transform_sample_counts(physeq_exp_pruned_genus, function (x) x/sum(x))
physeq_net_RA_genus_2 <- subset_taxa(physeq_net_RA_genus,rownames(otu_table(physeq_net_RA_genus))%in%names(netprops_partial$clustering$clust1))

RA_table_genus_net <- as.data.frame(otu_table(physeq_net_RA_genus_2))
tidy_RA_genus_net <- data.frame()
for (x in 1:length(colnames(RA_table_genus_net))) {
  current <- as.data.frame(RA_table_genus_net[,x]) #RA
  current[,2] <- colnames(RA_table_genus_net)[x] #site
  current[,3] <- sample_data(physeq_net_RA_genus_2)[rownames(sample_data(physeq_net_RA_genus_2))==colnames(RA_table_genus_net)[x],"Zone"] #Zone
  current[,4] <- tax_table(physeq_net_RA_genus_2)[,"Genus"] #Genus
  current[,5] <- rownames(tax_table(physeq_net_RA_genus_2)[,"Genus"]) #ASV (for blank names)
  tidy_RA_genus_net <- rbind(tidy_RA_genus_net,current)
}
colnames(tidy_RA_genus_net) <- c("RA","Site","Zone","Genus","ASV")
#rename the unlabelled
for (n in 1:nrow(tidy_RA_genus_net)) {
  if (as.logical(tidy_RA_genus_net[n,"Genus"] == "")) {
    tidy_RA_genus_net[n,"Genus"] <- tidy_RA_genus_net[n,"ASV"]
  }
  else {
    next
  }
}
#Add clustering
for (n in 1:nrow(tidy_RA_genus_net)) {
  tidy_RA_genus_net[n,"intact_cluster"] <- as.numeric(netprops_partial$clustering$clust1[tidy_RA_genus_net[n,"ASV"]])
  tidy_RA_genus_net[n,"degraded_cluster"] <- as.numeric(netprops_partial$clustering$clust2[tidy_RA_genus_net[n,"ASV"]])
}
tidy_RA_genus_net[,"intact_cluster"] <- as.factor(tidy_RA_genus_net[,"intact_cluster"])
tidy_RA_genus_net[,"degraded_cluster"] <- as.factor(tidy_RA_genus_net[,"degraded_cluster"])

#Plot it
ASV.labs <- tidy_RA_genus_net$Genus
names(ASV.labs) <- tidy_RA_genus_net$ASV
Network_sig <- ggplot(tidy_RA_genus_net, aes(x = Zone, y = RA)) + geom_boxplot(aes(fill=degraded_cluster)) + 
  theme_minimal() + theme(legend.position = "none", plot.title = element_text(hjust = 0.5)) +  labs(title = "Relative abundance of Genera") +
  geom_signif(comparisons = list(c("Intact","Degraded"),c("Degraded","Restored"),c("Intact","Restored")),map_signif_level=TRUE, colour="black",step_increase = 0.2) +
  facet_wrap(~ASV, labeller = labeller(ASV = ASV.labs)) + ylim(0,0.15) + 
  scale_fill_manual(values = netcolours)

#Seems to support the idea. Want a table that can give more detail

#ASV #mean_intact #mean_degraded #p-value #cluster_intact #cluster_degraded #taxonomy...
#Using wilcox test like default for geom_signif
Net_Genus_Table <- as.data.frame(matrix(nrow = nrow(RA_table_genus_net),ncol = 12,dimnames = list(NULL,c("ASV","mean_intact","mean_degraded","p-value","cluster_intact","cluster_degraded","Domain","Phylum","Class","Order","Family","Genus"))))
for (x in 1:nrow(Net_Genus_Table)) {
  Net_Genus_Table[x,"ASV"] <- rownames(RA_table_genus_net)[x]
  Net_Genus_Table[x,"mean_intact"] <- mean(tidy_RA_genus_net[tidy_RA_genus_net$ASV==Net_Genus_Table[x,"ASV"] & tidy_RA_genus_net$Zone =="Intact","RA"])
  Net_Genus_Table[x,"mean_degraded"] <- mean(tidy_RA_genus_net[tidy_RA_genus_net$ASV==Net_Genus_Table[x,"ASV"] & tidy_RA_genus_net$Zone =="Degraded","RA"])
  Net_Genus_Table[x,"p-value"] <- wilcox.test(tidy_RA_genus_net[tidy_RA_genus_net$ASV==Net_Genus_Table[x,"ASV"] & tidy_RA_genus_net$Zone =="Intact","RA"],tidy_RA_genus_net[tidy_RA_genus_net$ASV==Net_Genus_Table[x,"ASV"] & tidy_RA_genus_net$Zone =="Degraded","RA"])$p.value
  Net_Genus_Table[x,"cluster_intact"] <- as.numeric(netprops_partial$clustering$clust1[Net_Genus_Table[x,"ASV"]])
  Net_Genus_Table[x,"cluster_degraded"] <- as.numeric(netprops_partial$clustering$clust2[Net_Genus_Table[x,"ASV"]])
  Net_Genus_Table[x,c("Domain","Phylum","Class","Order","Family","Genus")] <- tax_table(physeq_net_RA_genus_2)[Net_Genus_Table[x,"ASV"],1:6]
  }
#correct p-values for multiple testing
Net_Genus_Table[,"p-value"] <- p.adjust(Net_Genus_Table[,"p-value"],method = "BH")

#Strong relationship between abundance in intact or degraded and their cluster
table(Net_Genus_Table[Net_Genus_Table$`p-value` < 0.05,"cluster_degraded"],(Net_Genus_Table[Net_Genus_Table$`p-value` < 0.05,"mean_intact"] > Net_Genus_Table[Net_Genus_Table$`p-value` < 0.05,"mean_degraded"]))

ASV.labs <- Net_Genus_Table$Genus
names(ASV.labs) <- Net_Genus_Table$ASV
Network_sig_diffs <- ggplot(tidy_RA_genus_net[tidy_RA_genus_net$ASV%in%Net_Genus_Table[Net_Genus_Table$`p-value` < 0.05,"ASV"],], aes(x = Zone, y = RA)) + geom_boxplot(aes(fill=degraded_cluster)) + 
  theme_minimal() + theme(legend.position = "none", plot.title = element_text(hjust = 0.5)) +  labs(title = "Relative abundance of significantly different Genera in network") +
  geom_signif(comparisons = list(c("Intact","Degraded"),c("Degraded","Restored"),c("Intact","Restored")),map_signif_level=TRUE, colour="black",step_increase = 0.2) +
  facet_wrap(~ASV, labeller = labeller(ASV = ASV.labs)) + ylim(0,0.15) + 
  scale_fill_manual(values = netcolours)

ggsave(filename = paste("Supplementary Figure S8.eps",sep=""), Network_sig_diffs, width = 16, height = 9, dpi = 300)

#####

#Graph the soil chem data
soil_chem <- subset(metadata_raw, select = c("Zone","pH.KCl","PBray1","PBray2","Na","K","Ca","Mg","percent.Ca","percent.Mg","percent.K","percent.Na","Ratio.Ca.Mg","Ca.Mg.over.K","Ratio.Mg.K","S.Value","ratio.Na.K","CEC","Density","S","Clay","Silt","Sand","NO3","NH4","C"))

#Create a table to give human readable titles and units for the graphs
soil_chem_annot <- as.data.frame(matrix(nrow = 25,ncol = 3, dimnames = list(NULL,c("Variable","Name","Unit"))))
soil_chem_annot[,"Variable"] <- c("pH.KCl","PBray1","PBray2","Na","K","Ca","Mg","percent.Ca","percent.Mg","percent.K","percent.Na","Ratio.Ca.Mg","Ca.Mg.over.K","Ratio.Mg.K","S.Value","ratio.Na.K","CEC","Density","S","Clay","Silt","Sand","NO3","NH4","C")
soil_chem_annot[,"Name"] <- c("pH (KCl)","P (PBray1)","P (PBray2)","Na","K","Ca","Mg","Percent Ca","Percent Mg","Percent K","Percent Na","Ca:Mg","(Ca+Mg)/K","Mg:K","S-Value (Ca+Mg+K+Na)","Na:K","CEC (Ca+Mg+K+Na+H)","Density","S","Clay","Silt","Sand","NO3","NH4","C")
soil_chem_annot[,"Unit"] <- c("pH","mg/kg","mg/kg","mg/kg","mg/kg","mg/kg","mg/kg","%","%","%","%","","","","","","","g/ml","mg/kg","% Texture","% Texture","% Texture","mg/kg","mg/kg","%")

#Combined figure showing the variables that are important for the RDA
nbchem <- list()
for (VAR in c("pH.KCl","Ratio.Ca.Mg","Density")) {
  graph <- ggplot(soil_chem, aes_string(x = "Zone", y = VAR)) + geom_boxplot(aes(fill=Zone)) + scale_colour_manual(values=c("red", "green","blue")) + 
    theme_minimal() + theme(legend.position = "none", plot.title = element_text(hjust = 0.5)) +  labs(title = paste(soil_chem_annot[soil_chem_annot[,"Variable"]==VAR,"Name"])) +
    geom_signif(comparisons = list(c("Intact","Degraded"),c("Degraded","Restored"),c("Intact","Restored")), y_position = c(max(soil_chem[VAR])*1.05,(max(soil_chem[VAR]))*1.1,(max(soil_chem[VAR]))*1.15),map_signif_level=TRUE, colour="black") +
    ylab(label = paste(soil_chem_annot[soil_chem_annot[,"Variable"]==VAR,"Unit"])) + scale_fill_manual(values = site_colours) +
    xlab(label = NULL)
  nbchem[VAR] <- list(graph)
}
nbchem_graph <- grid.arrange(nbchem[[1]],nbchem[[2]],nbchem[[3]],ncol=3)

#Figure save
RDA_Phylum <- RDA_RA_Phylum_no_overlap + labs(tag = "A")
RDA_Genus <- RDA_RA_Genus_no_overlap + labs(tag = "B")
Soil_pH <- nbchem[["pH.KCl"]] + labs(tag = "C")
Soil_Ratio.Ca.Mg <- nbchem[["Ratio.Ca.Mg"]] + labs(tag = "D")
Soil_Density <- nbchem[["Density"]] + labs(tag = "E")
p1 <- grid.arrange(RDA_Phylum,RDA_Genus,ncol=2)
p2 <- grid.arrange(Soil_pH,Soil_Ratio.Ca.Mg,Soil_Density,ncol=3)
p3 <- grid.arrange(p1,p2,nrow=2)
ggsave(filename = paste("Figure 5.eps",sep=""), p3, width = 12, height = 8, dpi = 300)


#####

#PCA of soil physicochemistry

#Get the relevant data
soil_pca_data <- subset(metadata_raw, select = colnames(metadata_raw)[5:ncol(metadata_raw)])

#Normalise the soil chemistry
soil_pca_data_norm <- decostand(soil_pca_data, "stand")

#PCA (external scaling)
pca_res2 <- prcomp(soil_pca_data_norm, scale. = FALSE)
dtp2 <- data.frame('Zone' = as.character(metadata_raw$Zone), pca_res2$x[,1:2])
PCAloadings2 <- data.frame(Variables = rownames(pca_res2$rotation), pca_res2$rotation)

#Keep the ordering
dtp2$Zone <- factor(dtp2$Zone, levels = unique(dtp2$Zone), ordered = TRUE)

#plot
Zone_graph2 <- ggplot(data = dtp2) + 
  geom_point(aes(x = PC1, y = PC2, col = Zone), size=3) + 
  theme_minimal() + 
  scale_colour_manual(values = site_colours) + 
  stat_ellipse(aes(x = PC1, y = PC2, col = Zone)) +
  theme(legend.position = "none")
Zone_graph_loadings2 <- Zone_graph2 + 
  geom_segment(data = PCAloadings2, aes(x = 0, y = 0, xend = (PC1*10), yend = (PC2*10)), arrow = arrow(length = unit(1/2, "picas")), color = "black") + 
  geom_text_repel(data=PCAloadings2, aes(label=Variables, x = PCAloadings2[,2]*10, y=PCAloadings2[,3]*10))

#Save figure (with previous PCoA)
Fig2 <- grid.arrange(Zone_graph_loadings2 + labs(tag = "A"), PCoA_phyloseq_Jaccard + labs(tag = "B"), nrow = 1)
ggsave(filename = paste("Figure 2.eps",sep=""), Fig2, width = 12, height = 6.75, dpi = 300)

######iButton Analysis#####

###iButton trends###

#Full time changes
sites <- c("Intact","Degraded","Restored")
annual_graphs <- list()
for (n in 1:length(sites)) {
  graph <- ggplot(data[data$Zone==sites[n],], aes(Date)) + geom_point(aes(y = RH), color = "light blue", alpha = 0.25, size = .4) + geom_smooth(aes(y = RH), color = "blue") + geom_point(aes(y = Temperature), color = "pink", alpha = 0.25,size = .4) + geom_smooth(aes(y = Temperature), color = "red") + labs(title = sites[n], y = NULL, x = "Month") + scale_y_continuous(limits = c(0,100), breaks = c(0,10,20,30,40,50,60,70,80,90,100)) + theme_minimal()
  annual_graphs[sites[n]] <- list(graph)
  rm(graph)
}

#Daily changes
sites <- c("Intact","Degraded","Restored")
daily_graphs <- list()
for (n in 1:length(sites)) {
  graph <- ggplot(data[data$Zone==sites[n],], aes(Time)) + geom_point(aes(y = RH), color = "light blue", alpha = 0.25, size = .4) + 
    geom_smooth(aes(y = RH), color = "blue") + geom_point(aes(y = Temperature), color = "pink", alpha = 0.25,size = .4) + 
    geom_smooth(aes(y = Temperature), color = "red") + labs(title = sites[n], y = NULL, x = "Time") + scale_y_continuous(limits = c(0,100), breaks = c(0,10,20,30,40,50,60,70,80,90,100)) + 
    theme_minimal() + theme(axis.text.x=element_text(angle=15, hjust=1)) +
    scale_x_datetime(breaks = "2 hour", minor_breaks = "1 hour", date_labels = "%H:%M",limits = c(as.POSIXct("00:00:00", format="%H:%M:%S",origin = "1960-01-01" ),as.POSIXct("23:59:59", format="%H:%M:%S",origin = "1960-01-01")))
  daily_graphs[sites[n]] <- list(graph)
  rm(graph)
}

#Save figure
image <- grid.arrange(annual_graphs[["Intact"]] + labs(tag = "A"), annual_graphs[["Degraded"]] + labs(tag = "B"),annual_graphs[["Restored"]] + labs(tag = "C"), daily_graphs[["Intact"]] + labs(tag = "D"), daily_graphs[["Degraded"]] + labs(tag = "E"), daily_graphs[["Restored"]] + labs(tag = "F"), ncol = 3)
ggsave(filename = paste("Supplemental Figure S2.eps",sep=""), image, width = 16, height = 9, dpi = 300, device = cairo_ps)

###iButton comparisons###

#Make boxplots
RH_boxplot <- ggplot(data, aes(x = Zone, y = RH)) + 
  geom_boxplot(aes(fill=Zone)) + 
  scale_fill_manual(values = site_colours) +
  ylab(label = "Relative humidity (%)") +
  xlab(label = NULL) +
  theme_minimal() + scale_y_continuous(breaks = c(0,10,20,30,40,50,60,70,80,90,100)) + 
  theme(legend.position = "top") + 
  geom_signif(comparisons = list(c("Intact","Degraded"),c("Degraded","Restored"),c("Intact","Restored")), y_position = c(105,111,117), map_signif_level=TRUE, colour="black")

Temp_boxplot <- ggplot(data, aes(x = Zone, y = Temperature)) + 
  geom_boxplot(aes(fill=Zone)) + 
  scale_fill_manual(values = site_colours) + 
  ylab(label = "Temperature (°C)") +
  xlab(label = NULL) +
  theme_minimal() + scale_y_continuous(breaks = c(0,10,20,30,40,50,60)) + 
  theme(legend.position = "top") + 
  geom_signif(comparisons = list(c("Intact","Degraded"),c("Degraded","Restored"),c("Intact","Restored")), y_position = c(60,65,70), map_signif_level=TRUE, colour="black")

#Make summary table with daily maxima and minima
data$YYYYMMDD <- str_extract(data$Date, "^.{10}")
daily_data <- data.frame()
for (x in unique(data$YYYYMMDD)) {
  for (y in unique(data$Zone)) {
    current <- data.frame()
    current[1,"Date"] <- as.POSIXct(x,origin = "1970-01-01")
    current[1,"Zone"] <- y
    current[1,c("Temp_Max","Temp_Min")] <- summary(data[data$YYYYMMDD==current[1,"Date"] & data$Zone==y,"Temperature"])[c(6,1)]
    current[1,c("RH_Max","RH_Min")] <- summary(data[data$YYYYMMDD==current[1,"Date"] & data$Zone==y,"RH"])[c(6,1)]
    daily_data <- rbind(daily_data,current)
  }
}

#Plot min/max values
Temp_maxmin <- ggplot(daily_data, aes(Date)) + 
  stat_summary(aes(y = Temp_Max, color = Zone), fun=max, geom="line") +
  stat_summary(aes(y = Temp_Min, color = Zone), fun=min, geom="line",linetype = 'dashed') +
  labs(title = NULL, y = NULL, x = "Month") + 
  scale_y_continuous(breaks = c(0,10,20,30,40,50,60)) +
  scale_x_datetime(breaks = "1 month", minor_breaks = "1 week", date_labels = "%B") + 
  ylab(label = "Temperature (°C)") +
  theme_minimal() +
  theme(legend.position = "none")

RH_maxmin <- ggplot(daily_data, aes(Date)) + 
  stat_summary(aes(y = RH_Max, color = Zone), fun=max, geom="line") +
  stat_summary(aes(y = RH_Min, color = Zone), fun=min, geom="line",linetype = 'dashed') +
  labs(title = NULL, y = NULL, x = "Month") + 
  scale_y_continuous(limits = c(0,100), breaks = c(0,10,20,30,40,50,60,70,80,90,100)) +
  scale_x_datetime(breaks = "1 month", minor_breaks = "1 week", date_labels = "%B") + 
  ylab(label = "Relative humidity (%)") +
  theme_minimal() +
  theme(legend.position = "none")

#Plot differences
Temp_comparison <- data.frame()
#max
Temp_comparison<- rbind(Temp_comparison,data.frame("Value" = daily_data[daily_data$Zone=="Degraded","Temp_Max"]-daily_data[daily_data$Zone=="Intact","Temp_Max"],
                                                   "Comparison" = "Degraded\nvs\nIntact","Type" = "Maximum Temperature"))
Temp_comparison<- rbind(Temp_comparison,data.frame("Value" = daily_data[daily_data$Zone=="Degraded","Temp_Max"]-daily_data[daily_data$Zone=="Restored","Temp_Max"],
                                                   "Comparison" = "Degraded\nvs\nRestored","Type" = "Maximum Temperature"))
Temp_comparison<- rbind(Temp_comparison,data.frame("Value" = daily_data[daily_data$Zone=="Restored","Temp_Max"]-daily_data[daily_data$Zone=="Intact","Temp_Max"],
                                                   "Comparison" = "Restored\nvs\nIntact","Type" = "Maximum Temperature"))
#min
Temp_comparison<- rbind(Temp_comparison,data.frame("Value" = daily_data[daily_data$Zone=="Degraded","Temp_Min"]-daily_data[daily_data$Zone=="Intact","Temp_Min"],
                                                   "Comparison" = "Degraded\nvs\nIntact","Type" = "Minimum Temperature"))
Temp_comparison<- rbind(Temp_comparison,data.frame("Value" = daily_data[daily_data$Zone=="Degraded","Temp_Min"]-daily_data[daily_data$Zone=="Restored","Temp_Min"],
                                                   "Comparison" = "Degraded\nvs\nRestored","Type" = "Minimum Temperature"))
Temp_comparison<- rbind(Temp_comparison,data.frame("Value" = daily_data[daily_data$Zone=="Restored","Temp_Min"]-daily_data[daily_data$Zone=="Intact","Temp_Min"],
                                                   "Comparison" = "Restored\nvs\nIntact","Type" = "Minimum Temperature"))
#together
Temp_differences <- ggplot(Temp_comparison,aes(y = Value, x = Comparison)) +
  geom_hline(yintercept=0) +
  geom_boxplot() +
  facet_wrap(~Type) +
  theme_minimal() + 
  ylab("Daily mean temperature difference (°C)")+
  xlab("")

RH_comparison <- data.frame()
#max
RH_comparison<- rbind(RH_comparison,data.frame("Value" = daily_data[daily_data$Zone=="Degraded","RH_Max"]-daily_data[daily_data$Zone=="Intact","RH_Max"],
                                               "Comparison" = "Degraded\nvs\nIntact","Type" = "Maximum Relative Humidity"))
RH_comparison<- rbind(RH_comparison,data.frame("Value" = daily_data[daily_data$Zone=="Degraded","RH_Max"]-daily_data[daily_data$Zone=="Restored","RH_Max"],
                                               "Comparison" = "Degraded\nvs\nRestored","Type" = "Maximum Relative Humidity"))
RH_comparison<- rbind(RH_comparison,data.frame("Value" = daily_data[daily_data$Zone=="Restored","RH_Max"]-daily_data[daily_data$Zone=="Intact","RH_Max"],
                                               "Comparison" = "Restored\nvs\nIntact","Type" = "Maximum Relative Humidity"))
#min
RH_comparison<- rbind(RH_comparison,data.frame("Value" = daily_data[daily_data$Zone=="Degraded","RH_Min"]-daily_data[daily_data$Zone=="Intact","RH_Min"],
                                               "Comparison" = "Degraded\nvs\nIntact","Type" = "Minimum Relative Humidity"))
RH_comparison<- rbind(RH_comparison,data.frame("Value" = daily_data[daily_data$Zone=="Degraded","RH_Min"]-daily_data[daily_data$Zone=="Restored","RH_Min"],
                                               "Comparison" = "Degraded\nvs\nRestored","Type" = "Minimum Relative Humidity"))
RH_comparison<- rbind(RH_comparison,data.frame("Value" = daily_data[daily_data$Zone=="Restored","RH_Min"]-daily_data[daily_data$Zone=="Intact","RH_Min"],
                                               "Comparison" = "Restored\nvs\nIntact","Type" = "Minimum Relative Humidity"))
#together
RH_differences <- ggplot(RH_comparison,aes(y = Value, x = Comparison)) +
  geom_hline(yintercept=0) +
  geom_boxplot() +
  facet_wrap(~Type) +
  theme_minimal() + 
  ylab("Daily mean relative humidity difference (%)") +
  xlab("")

#Combine for figure
FigS3 <- grid.arrange(Temp_boxplot + labs(tag = "A"), Temp_maxmin + labs(tag = "B"), Temp_differences + labs(tag = "C"), ncol = 1)
ggsave(filename = paste("Supplemental Figure S3.eps",sep=""), FigS3, width = 9, height = 16, dpi = 300)
FigS4 <- grid.arrange(RH_boxplot + labs(tag = "A"), RH_maxmin + labs(tag = "B"), RH_differences + labs(tag = "C"), ncol = 1)
ggsave(filename = paste("Supplemental Figure S4.eps",sep=""), FigS4, width = 9, height = 16, dpi = 300)

###Summary Table###

#Summary value table
Weathertable <- data.frame()
Weathertable[1,1:15] <- c("",rep("RH",7),rep("Temperature",7))
Weathertable[2,1:15] <- c("",rep(c("Min.","1st Qu.","Median","Mean","3rd Qu.","Max.","sd"),2))
Weathertable[3,1:15] <- c("Study site",c(summary(data[,"RH"])[1:6], sd(data[,"RH"],na.rm = T)),c(summary(data[,"Temperature"])[1:6], sd(data[,"Temperature"],na.rm = T)))
Weathertable[4,1:15] <- c("Intact",c(summary(data[data$Zone=="Intact","RH"])[1:6], sd(data[data$Zone=="Intact","RH"],na.rm = T)),c(summary(data[data$Zone=="Intact","Temperature"])[1:6], sd(data[data$Zone=="Intact","RH"],na.rm = T)))
Weathertable[5,1:15] <- c("Degraded",c(summary(data[data$Zone=="Degraded","RH"])[1:6], sd(data[data$Zone=="Degraded","RH"],na.rm = T)),c(summary(data[data$Zone=="Degraded","Temperature"])[1:6], sd(data[data$Zone=="Degraded","RH"],na.rm = T)))
Weathertable[6,1:15] <- c("Restored",c(summary(data[data$Zone=="Restored","RH"])[1:6], sd(data[data$Zone=="Restored","RH"],na.rm = T)),c(summary(data[data$Zone=="Restored","Temperature"])[1:6], sd(data[data$Zone=="Restored","RH"],na.rm = T)))

#Save the table
write.table(Weathertable,file="Supplemental Table S2.csv",row.names = F,col.names = F,quote = T,sep = ",")


###Generate values for RDA according to the mean and standard deviation###

#Use the weather table summary statistics to generate a set of pseudo measurements for use with the RDA.
pseudomeasures <- as.data.frame(matrix(nrow = 35,ncol = 3,dimnames = list(NULL,c("State","RH","Temperature"))))
pseudomeasures[1:15,"State"] <- "Intact"
pseudomeasures[16:30,"State"] <- "Degraded"
pseudomeasures[31:35,"State"] <- "Restored"
#Need a starting value for the loop to work
pseudomeasures[,2:3] <- 0
#Loop so that readings are always within the 1Q and 3Q of their relevant measurements.
#Using quarter sd for temp because the sd is otherwise very large for a small range of averages because of day/night extremes and it's hard to get a distribution that fits.
#This gives a sense of the variation real readings should have but also prevents any extremes which could mess up the reading
set.seed(12345)
while(min(pseudomeasures[1:15,"RH"]) < as.numeric(Weathertable[Weathertable$V1 == "Intact",3]) || max(pseudomeasures[1:15,"RH"]) > as.numeric(Weathertable[Weathertable$V1 == "Intact",6])) {
  pseudomeasures[1:15,"RH"] <- rnorm(15,mean = as.numeric(Weathertable[Weathertable$V1 == "Intact",5]),sd = as.numeric(Weathertable[Weathertable$V1 == "Intact",8]))
}
while(min(pseudomeasures[1:15,"Temperature"]) < as.numeric(Weathertable[Weathertable$V1 == "Intact",10]) || max(pseudomeasures[1:15,"Temperature"]) > as.numeric(Weathertable[Weathertable$V1 == "Intact",13])) {
  pseudomeasures[1:15,"Temperature"] <- rnorm(15,mean = as.numeric(Weathertable[Weathertable$V1 == "Intact",12]),sd = 0.25*as.numeric(Weathertable[Weathertable$V1 == "Intact",15]))
}
while(min(pseudomeasures[16:30,"RH"]) < as.numeric(Weathertable[Weathertable$V1 == "Degraded",3]) || max(pseudomeasures[16:30,"RH"]) > as.numeric(Weathertable[Weathertable$V1 == "Degraded",6])) {
  pseudomeasures[16:30,"RH"] <- rnorm(15,mean = as.numeric(Weathertable[Weathertable$V1 == "Degraded",5]),sd = as.numeric(Weathertable[Weathertable$V1 == "Degraded",8]))
}
while(min(pseudomeasures[16:30,"Temperature"]) < as.numeric(Weathertable[Weathertable$V1 == "Degraded",10]) || max(pseudomeasures[16:30,"Temperature"]) > as.numeric(Weathertable[Weathertable$V1 == "Degraded",13])) {
  pseudomeasures[16:30,"Temperature"] <- rnorm(15,mean = as.numeric(Weathertable[Weathertable$V1 == "Degraded",12]),sd = 0.25*as.numeric(Weathertable[Weathertable$V1 == "Degraded",15]))
}
while(min(pseudomeasures[31:35,"RH"]) < as.numeric(Weathertable[Weathertable$V1 == "Restored",3]) || max(pseudomeasures[31:35,"RH"]) > as.numeric(Weathertable[Weathertable$V1 == "Restored",6])) {
  pseudomeasures[31:35,"RH"] <- rnorm(5,mean = as.numeric(Weathertable[Weathertable$V1 == "Restored",5]),sd = as.numeric(Weathertable[Weathertable$V1 == "Restored",8]))
}
while(min(pseudomeasures[31:35,"Temperature"]) < as.numeric(Weathertable[Weathertable$V1 == "Restored",10]) || max(pseudomeasures[31:35,"Temperature"]) > as.numeric(Weathertable[Weathertable$V1 == "Restored",13])) {
  pseudomeasures[31:35,"Temperature"] <- rnorm(5,mean = as.numeric(Weathertable[Weathertable$V1 == "Restored",12]),sd = 0.25*as.numeric(Weathertable[Weathertable$V1 == "Restored",15]))
}

write.table(pseudomeasures,file="Pseudo_measurements.csv",row.names = F,col.names = T,quote = T,sep = ",")

# To add RH and Temp max/min data, we need the averaged daily values
daily_data <- data.frame()
for (x in unique(data$Date)) {
  for (y in unique(data$Zone)) {
    current <- data.frame()
    current[1,"Date"] <- as.POSIXct(x,origin = "1970-01-01")
    current[1,"Zone"] <- y
    current[1,"Temp_Max"] <- max(data[data$Date==current[1,"Date"] & data$Zone==y,"Temperature"],na.rm = TRUE)
    current[1,"Temp_Min"] <- min(data[data$Date==current[1,"Date"] & data$Zone==y,"Temperature"],na.rm = TRUE)
    current[1,"RH_Max"] <- max(data[data$Date==current[1,"Date"] & data$Zone==y,"RH"],na.rm = TRUE)
    current[1,"RH_Min"] <- min(data[data$Date==current[1,"Date"] & data$Zone==y,"RH"],na.rm = TRUE)
    daily_data <- rbind(daily_data,current)
  }
}
daily_data$Zone <- factor(daily_data$Zone, levels = unique(daily_data$Zone), ordered = TRUE)

#Remove an infinity caused by a missing time point in degraded
daily_data <- subset(daily_data, !daily_data$Temp_Max==-Inf)

#Construct a table of mean and standard deviations of the values which can be used to generate values for the RDA
minmaxsummary <- data.frame()
minmaxsummary[1,1:29] <- c("",rep("Temp_Max",7),rep("Temp_Min",7),rep("RH_Max",7),rep("RH_Min",7))
minmaxsummary[2,1:29] <- c("",rep(c("Min.","1st Qu.","Median","Mean","3rd Qu.","Max.","sd"),4))
minmaxsummary[3,1:29] <- c("Intact",
                           c(summary(daily_data[,"Temp_Max"])[1:6],
                             sd(daily_data[,"Temp_Max"]),
                             summary(daily_data[,"Temp_Min"])[1:6],
                             sd(daily_data[,"Temp_Min"]),
                             summary(daily_data[,"RH_Max"])[1:6],
                             sd(daily_data[,"RH_Max"]),
                             summary(daily_data[,"RH_Min"]),
                             sd(daily_data[,"RH_Min"])))
minmaxsummary[4,1:29] <- c("Degraded",
                           c(summary(daily_data[daily_data$Zone=="Degraded","Temp_Max"])[1:6],
                             sd(daily_data[daily_data$Zone=="Degraded","Temp_Max"]),
                             summary(daily_data[daily_data$Zone=="Degraded","Temp_Min"])[1:6],
                             sd(daily_data[daily_data$Zone=="Degraded","Temp_Min"]),
                             summary(daily_data[daily_data$Zone=="Degraded","RH_Max"])[1:6],
                             sd(daily_data[daily_data$Zone=="Degraded","RH_Max"]),
                             summary(daily_data[daily_data$Zone=="Degraded","RH_Min"]),
                             sd(daily_data[daily_data$Zone=="Degraded","RH_Min"])))
minmaxsummary[5,1:29] <- c("Restored",
                           c(summary(daily_data[daily_data$Zone=="Restored","Temp_Max"])[1:6],
                             sd(daily_data[daily_data$Zone=="Restored","Temp_Max"]),
                             summary(daily_data[daily_data$Zone=="Restored","Temp_Min"])[1:6],
                             sd(daily_data[daily_data$Zone=="Restored","Temp_Min"]),
                             summary(daily_data[daily_data$Zone=="Restored","RH_Max"])[1:6],
                             sd(daily_data[daily_data$Zone=="Restored","RH_Max"]),
                             summary(daily_data[daily_data$Zone=="Restored","RH_Min"]),
                             sd(daily_data[daily_data$Zone=="Restored","RH_Min"])))

#Use the mean and standard deviation to create values for use with the RDA.
minmaxmeasures <- as.data.frame(matrix(nrow = 35,ncol = 5,dimnames = list(NULL,c("State","RH_Max","RH_Min","Temp_Max","Temp_Min"))))
minmaxmeasures[1:15,"State"] <- "Intact"
minmaxmeasures[16:30,"State"] <- "Degraded"
minmaxmeasures[31:35,"State"] <- "Restored"
#Need a starting value for the loop to work
minmaxmeasures[,2:5] <- 0
#Loop so that readings are always within the 1Q and 3Q of their relevant measurements.
#Using quarter sd for all which makes it easier to get a distribution that fits and it also prevents the maximums being lower than the minimums.
#This gives a sense of the variation real readings should have but also prevents any extremes which could mess up the reading
set.seed(12345)
while(min(minmaxmeasures[1:15,"RH_Max"]) < as.numeric(minmaxsummary[minmaxsummary$V1 == "Intact",17]) || max(minmaxmeasures[1:15,"RH_Max"]) > as.numeric(minmaxsummary[minmaxsummary$V1 == "Intact",20])) {
  minmaxmeasures[1:15,"RH_Max"] <- rnorm(15,mean = as.numeric(minmaxsummary[minmaxsummary$V1 == "Intact",19]),sd = 0.25*as.numeric(minmaxsummary[minmaxsummary$V1 == "Intact",22]))
}
while(min(minmaxmeasures[1:15,"RH_Min"]) < as.numeric(minmaxsummary[minmaxsummary$V1 == "Intact",24]) || max(minmaxmeasures[1:15,"RH_Min"]) > as.numeric(minmaxsummary[minmaxsummary$V1 == "Intact",27])) {
  minmaxmeasures[1:15,"RH_Min"] <- rnorm(15,mean = as.numeric(minmaxsummary[minmaxsummary$V1 == "Intact",26]),sd = 0.25*as.numeric(minmaxsummary[minmaxsummary$V1 == "Intact",29]))
}
while(min(minmaxmeasures[1:15,"Temp_Max"]) < as.numeric(minmaxsummary[minmaxsummary$V1 == "Intact",3]) || max(minmaxmeasures[1:15,"Temp_Max"]) > as.numeric(minmaxsummary[minmaxsummary$V1 == "Intact",6])) {
  minmaxmeasures[1:15,"Temp_Max"] <- rnorm(15,mean = as.numeric(minmaxsummary[minmaxsummary$V1 == "Intact",5]),sd = 0.25*as.numeric(minmaxsummary[minmaxsummary$V1 == "Intact",8]))
}
while(min(minmaxmeasures[1:15,"Temp_Min"]) < as.numeric(minmaxsummary[minmaxsummary$V1 == "Intact",10]) || max(minmaxmeasures[1:15,"Temp_Min"]) > as.numeric(minmaxsummary[minmaxsummary$V1 == "Intact",13])) {
  minmaxmeasures[1:15,"Temp_Min"] <- rnorm(15,mean = as.numeric(minmaxsummary[minmaxsummary$V1 == "Intact",12]),sd = 0.25*as.numeric(minmaxsummary[minmaxsummary$V1 == "Intact",15]))
}
while(min(minmaxmeasures[16:30,"RH_Max"]) < as.numeric(minmaxsummary[minmaxsummary$V1 == "Degraded",17]) || max(minmaxmeasures[16:30,"RH_Max"]) > as.numeric(minmaxsummary[minmaxsummary$V1 == "Degraded",20])) {
  minmaxmeasures[16:30,"RH_Max"] <- rnorm(15,mean = as.numeric(minmaxsummary[minmaxsummary$V1 == "Degraded",19]),sd = 0.25*as.numeric(minmaxsummary[minmaxsummary$V1 == "Degraded",22]))
}
while(min(minmaxmeasures[16:30,"RH_Min"]) < as.numeric(minmaxsummary[minmaxsummary$V1 == "Degraded",24]) || max(minmaxmeasures[16:30,"RH_Min"]) > as.numeric(minmaxsummary[minmaxsummary$V1 == "Degraded",27])) {
  minmaxmeasures[16:30,"RH_Min"] <- rnorm(15,mean = as.numeric(minmaxsummary[minmaxsummary$V1 == "Degraded",26]),sd = 0.25*as.numeric(minmaxsummary[minmaxsummary$V1 == "Degraded",29]))
}
while(min(minmaxmeasures[16:30,"Temp_Max"]) < as.numeric(minmaxsummary[minmaxsummary$V1 == "Degraded",3]) || max(minmaxmeasures[16:30,"Temp_Max"]) > as.numeric(minmaxsummary[minmaxsummary$V1 == "Degraded",6])) {
  minmaxmeasures[16:30,"Temp_Max"] <- rnorm(15,mean = as.numeric(minmaxsummary[minmaxsummary$V1 == "Degraded",5]),sd = 0.25*as.numeric(minmaxsummary[minmaxsummary$V1 == "Degraded",8]))
}
while(min(minmaxmeasures[16:30,"Temp_Min"]) < as.numeric(minmaxsummary[minmaxsummary$V1 == "Degraded",10]) || max(minmaxmeasures[16:30,"Temp_Min"]) > as.numeric(minmaxsummary[minmaxsummary$V1 == "Degraded",13])) {
  minmaxmeasures[16:30,"Temp_Min"] <- rnorm(15,mean = as.numeric(minmaxsummary[minmaxsummary$V1 == "Degraded",12]),sd = 0.25*as.numeric(minmaxsummary[minmaxsummary$V1 == "Degraded",15]))
}
while(min(minmaxmeasures[31:35,"RH_Max"]) < as.numeric(minmaxsummary[minmaxsummary$V1 == "Restored",17]) || max(minmaxmeasures[31:35,"RH_Max"]) > as.numeric(minmaxsummary[minmaxsummary$V1 == "Restored",20])) {
  minmaxmeasures[31:35,"RH_Max"] <- rnorm(5,mean = as.numeric(minmaxsummary[minmaxsummary$V1 == "Restored",19]),sd = 0.25*as.numeric(minmaxsummary[minmaxsummary$V1 == "Restored",22]))
}
while(min(minmaxmeasures[31:35,"RH_Min"]) < as.numeric(minmaxsummary[minmaxsummary$V1 == "Restored",24]) || max(minmaxmeasures[31:35,"RH_Min"]) > as.numeric(minmaxsummary[minmaxsummary$V1 == "Restored",27])) {
  minmaxmeasures[31:35,"RH_Min"] <- rnorm(5,mean = as.numeric(minmaxsummary[minmaxsummary$V1 == "Restored",26]),sd = 0.25*as.numeric(minmaxsummary[minmaxsummary$V1 == "Restored",29]))
}
while(min(minmaxmeasures[31:35,"Temp_Max"]) < as.numeric(minmaxsummary[minmaxsummary$V1 == "Restored",3]) || max(minmaxmeasures[31:35,"Temp_Max"]) > as.numeric(minmaxsummary[minmaxsummary$V1 == "Restored",6])) {
  minmaxmeasures[31:35,"Temp_Max"] <- rnorm(5,mean = as.numeric(minmaxsummary[minmaxsummary$V1 == "Restored",5]),sd = 0.25*as.numeric(minmaxsummary[minmaxsummary$V1 == "Restored",8]))
}
while(min(minmaxmeasures[31:35,"Temp_Min"]) < as.numeric(minmaxsummary[minmaxsummary$V1 == "Restored",10]) || max(minmaxmeasures[31:35,"Temp_Min"]) > as.numeric(minmaxsummary[minmaxsummary$V1 == "Restored",13])) {
  minmaxmeasures[31:35,"Temp_Min"] <- rnorm(5,mean = as.numeric(minmaxsummary[minmaxsummary$V1 == "Restored",12]),sd = 0.25*as.numeric(minmaxsummary[minmaxsummary$V1 == "Restored",15]))
}

write.table(minmaxmeasures,file="minmaxmeasures.csv",row.names = F,col.names = T,quote = T,sep = ",")
